{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os, gc\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Timer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/kyletian/kaggle/jane-street-project/data\")\n",
    "import kaggle_evaluation.jane_street_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    seed = 42\n",
    "    target_col = \"responder_6\"\n",
    "    feature_cols = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "    # feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "    model_paths = [\n",
    "        #\"/kaggle/input/js24-train-gbdt-model-with-lags-singlemodel/result.pkl\",\n",
    "        #\"/kaggle/input/js24-trained-gbdt-model/result.pkl\",\n",
    "        \"/kaggle/input/js-xs-nn-trained-model\",\n",
    "    ]\n",
    "    ckpt_path = \"/home/kyletian/kaggle/jane-street-project/code/NN/checkpoints/epoch=17-step=22032.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom R2 metric for validation\n",
    "def r2_val(y_true, y_pred, sample_weight):\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
    "    return r2\n",
    "\n",
    "\n",
    "class NN(LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.BatchNorm1d(in_dim))\n",
    "            if i > 0:\n",
    "                layers.append(nn.SiLU())\n",
    "            if i < len(dropouts):\n",
    "                layers.append(nn.Dropout(dropouts[i]))\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            # layers.append(nn.ReLU())\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, 1))  # 输出层\n",
    "        layers.append(nn.Tanh())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 5 * self.model(x).squeeze(-1)  # 输出为一维张量\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w  # 考虑样本权重\n",
    "        loss = loss.mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w\n",
    "        loss = loss.mean()\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        self.validation_step_outputs.append((y_hat, y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        if self.trainer.sanity_checking:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        else:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            # r2_val\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n",
    "                                                               verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.7.7 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint checkpoints/epoch=17-step=22032.ckpt`\n"
     ]
    }
   ],
   "source": [
    "model = NN.load_from_checkpoint(CONFIG.ckpt_path)\n",
    "model.to(\"cuda:0\")\n",
    "models = [model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ags_ : pl.DataFrame | None = None\n",
    "    \n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    predictions = test.select(\n",
    "        'row_id',\n",
    "        pl.lit(0.0).alias('responder_6'),\n",
    "    )\n",
    "    symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n",
    "\n",
    "    if not lags is None:\n",
    "        lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up last record of previous date\n",
    "        test = test.join(lags, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n",
    "        # print(a)\n",
    "    else:\n",
    "        test = test.with_columns(\n",
    "            ( pl.lit(0.0).alias(f'responder_{idx}_lag_1') for idx in range(9) )\n",
    "        )\n",
    "    \n",
    "    preds = np.zeros((test.shape[0],))\n",
    "    # for i, model in enumerate(tqdm(models)):\n",
    "    #     preds += model.predict(test[CONFIG.feature_cols].to_pandas()) / len(models)\n",
    "    test_input = test[CONFIG.feature_cols].to_pandas()\n",
    "    test_input = test_input.fillna(method = 'ffill').fillna(0)\n",
    "    test_input = torch.FloatTensor(test_input.values).to(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        for i, nn_model in enumerate(tqdm(models)):\n",
    "            nn_model.eval()\n",
    "            preds += nn_model(test_input).cpu().numpy() / len(models)\n",
    "    print(f\"predict> preds.shape =\", preds.shape)\n",
    "    \n",
    "    predictions = \\\n",
    "    test.select('row_id').\\\n",
    "    with_columns(\n",
    "        pl.Series(\n",
    "            name   = 'responder_6', \n",
    "            values = np.clip(preds, a_min = -5, a_max = 5),\n",
    "            dtype  = pl.Float64,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The predict function must return a DataFrame\n",
    "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
    "    # with columns 'row_id', 'responer_6'\n",
    "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
    "    # and as many rows as the test data.\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c2bae64cd247fdb52766b030043d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict> preds.shape = (39,)\n"
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/Users/kyleee/code/project/kaggle_competition/data/test.parquet',\n",
    "            '/Users/kyleee/code/project/kaggle_competition/data/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
